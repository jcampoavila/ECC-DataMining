{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# SCRIPT TO TEST K NEAREST NEIGHBOURS MODELS\n",
    "Configuration of cross validation<br>\n",
    "Execution of cross validation<br>\n",
    "Results of cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# Maximise the width of text boxes\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Python version and rest of packages needed\n",
    "\n",
    "import sys\n",
    "# print('Python: {}'.format(sys.version))\n",
    "import scipy\n",
    "# print('scipy: {}'.format(scipy.__version__))\n",
    "import numpy as np\n",
    "# print('numpy: {}'.format(np.__version__))\n",
    "import matplotlib as mat\n",
    "# print('matplotlib: {}'.format(mat.__version__))\n",
    "import pandas as pd\n",
    "# print('pandas: {}'.format(pd.__version__))\n",
    "import sklearn as sk\n",
    "# print('sklearn: {}'.format(sk.__version__))\n",
    "import pyreadstat\n",
    "# print('pyreadstat: {}'.format(pyreadstat.__version__))\n",
    "import imblearn as im\n",
    "# print('imblearn: {}'.format(im.__version__))\n",
    "import joblib\n",
    "# print('joblib: {}'.format(joblib.__version__))\n",
    "import graphviz\n",
    "# print('graphviz: {}'.format(graphviz.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import functions from packages\n",
    "\n",
    "from collections import Counter\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from time import process_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset and visualize dataset\n",
    "\n",
    "df = pd.read_csv('../INPUT_dataset/BDsocioeconomic_dummy.csv',delimiter=',',low_memory=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enumerate columns\n",
    "\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some statistics about imbalanced class\n",
    "suicidal_behaviour_rate = df.loc[df['Class_suicidal_behaviour']==1].shape[0]/df.shape[0]*100\n",
    "non_suicidal_behaviour_rate = df.loc[df['Class_suicidal_behaviour']==0].shape[0]/df.shape[0]*100\n",
    "n_non_yes_suicidal_behaviour = Counter(df['Class_suicidal_behaviour'])\n",
    "print('The rate of non suicidal behaviour (0) is: {:.2f}%'.format(non_suicidal_behaviour_rate))\n",
    "print('The rate of suicidal behaviour (1) is: {:.2f}%'.format(suicidal_behaviour_rate))\n",
    "print('Number of instances of each class:')\n",
    "print(n_non_yes_suicidal_behaviour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise an instance to see what it looks like\n",
    "first_instance = df.iloc[0].drop(columns=['Class_suicidal_behaviour'])\n",
    "first_instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_targets = train['Clase_suicidio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy of the original dataset\n",
    "dataset = df.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset with the observations. Independent variables without the class\n",
    "dataset_values = dataset.drop(columns=['Class_suicidal_behaviour'])\n",
    "# dataset with the classes. Dependent variable\n",
    "dataset_targets = pd.DataFrame(dataset['Class_suicidal_behaviour'], columns=['Class_suicidal_behaviour'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of the cross-validation process\n",
    "folds = 10\n",
    "repetitions = 3\n",
    "seed = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration of the cross-validation process\n",
    "cv = RepeatedStratifiedKFold(n_splits=folds, n_repeats=repetitions, random_state=seed)\n",
    "\n",
    "# Setting the importance of classes.\n",
    "# The cost of making a mistake missing a suicidal behaviour is higher (False Negative are worse than False Positive)\n",
    "param_class_weight_min = 0.2\n",
    "param_class_weight_max = 0.8\n",
    "class_weight = {0:param_class_weight_min, 1:param_class_weight_max}\n",
    "\n",
    "# Setting of the KNeighborsClassifier algorithm\n",
    "# This method can not use the class weight defined\n",
    "\n",
    "param_n_neighbors = 5\n",
    "param_weights = 'uniform'\n",
    "\n",
    "this_model = KNeighborsClassifier(\n",
    "                                     n_neighbors=param_n_neighbors,\n",
    "                                     weights=param_weights\n",
    "                                 )\n",
    "\n",
    "# for debugging results in every iteration (0=none, 1=low, 2=high)\n",
    "debug_level = 2\n",
    "\n",
    "# we store all intermediate results \n",
    "total_experiments = folds * repetitions\n",
    "all_conf_matrix = np.zeros((total_experiments,2,2))\n",
    "all_accuracy = np.zeros(total_experiments)\n",
    "all_sensitivity = np.zeros(total_experiments)\n",
    "all_specificity = np.zeros(total_experiments)\n",
    "all_PPV_precision = np.zeros(total_experiments)\n",
    "all_NPV = np.zeros(total_experiments)\n",
    "all_FNR = np.zeros(total_experiments)\n",
    "all_F1 = np.zeros(total_experiments)\n",
    "\n",
    "current_experiment = 0\n",
    "\n",
    "\n",
    "# Start timer \n",
    "timer_start = process_time() \n",
    "\n",
    "# for each of the training and test combinations generated by the cross validation process\n",
    "# train_ix stores the index of the experiences that will be used for train\n",
    "# test_ix stores the index of the experiences that will be used for test\n",
    "for train_ix, test_ix in cv.split(dataset_values, dataset_targets):\n",
    "    \n",
    "    # we construct the training sets by separating observations from classes\n",
    "    # for this we use the chosen training indices train_ix\n",
    "    train_X = dataset_values.iloc[train_ix]\n",
    "    train_Y = dataset_targets.iloc[train_ix]\n",
    "    \n",
    "    # we construct the test sets by separating observations from classes\n",
    "    # for this we use the indexes chosen for test_ix \n",
    "    test_X = dataset_values.iloc[test_ix]\n",
    "    test_Y = dataset_targets.iloc[test_ix]\n",
    "         \n",
    "    # some information\n",
    "    if debug_level>=1:\n",
    "        print('\\n')\n",
    "        print('Experiment %d out of %d' % (current_experiment+1,total_experiments))\n",
    "        suicidal_behaviour_rate = train_Y.loc[train_Y['Class_suicidal_behaviour']==1].shape[0]/train_Y.shape[0]*100\n",
    "        n_non_yes_suicidal_behaviour = Counter(train_Y['Class_suicidal_behaviour'])\n",
    "        print('The rate of suicidal behaviour (1) BEFORE rebalancing is: {:.2f}%'.format(suicidal_behaviour_rate))\n",
    "        print('Number of instances of each class')\n",
    "        print(n_non_yes_suicidal_behaviour)      \n",
    "    \n",
    "    # to do the rebalancing, it works better if everything is scaled between 0 and 1\n",
    "    this_scaler = preprocessing.MinMaxScaler()\n",
    "    this_scaler = this_scaler.fit(train_X)\n",
    "    train_X = this_scaler.transform(train_X)\n",
    "\n",
    "    # we rebalance the dataset\n",
    "    param_SMOTEsampling_strategy=0.1\n",
    "    param_Undersampling_strategy=0.2\n",
    "    oversampling_conf = SMOTE(sampling_strategy=param_SMOTEsampling_strategy,random_state=seed)\n",
    "    undersamplinf_conf = RandomUnderSampler(sampling_strategy=param_Undersampling_strategy,random_state=seed)\n",
    "    rebalance_steps = [('o', oversampling_conf), ('u', undersamplinf_conf)]\n",
    "    rebalance_pipeline = Pipeline(steps=rebalance_steps)\n",
    "    train_X, train_Y = rebalance_pipeline.fit_resample(train_X, train_Y)\n",
    "    \n",
    "    # This model does not need normalised data\n",
    "    # so we return the data to their original values\n",
    "    train_X = this_scaler.inverse_transform(train_X)\n",
    "\n",
    "    # In models where the data does NOT have to be normalised\n",
    "    # rounding columns that had INTEGER values can help produce a better model\n",
    "    train_X[:,0]  = list(map(round, train_X[:,0]))    # Sex_M0_F1\n",
    "    train_X[:,2]  = list(map(round, train_X[:,2]))    # Day_in_week\n",
    "    train_X[:,3]  = list(map(round, train_X[:,3]))    # Day_in_month\n",
    "    train_X[:,4]  = list(map(round, train_X[:,4]))    # Month\n",
    "    train_X[:,5]  = list(map(round, train_X[:,5]))    # Quarter\n",
    "    train_X[:,6]  = list(map(round, train_X[:,6]))    # Week_in_year\n",
    "    train_X[:,7]  = list(map(round, train_X[:,7]))    # Week_in_month\n",
    "    train_X[:,8]  = list(map(round, train_X[:,8]))    # Working_day\n",
    "    train_X[:,9]  = list(map(round, train_X[:,9]))    # Day1_Night2\n",
    "    train_X[:,17] = list(map(round, train_X[:,17]))   # Num_requests_last_months\n",
    "    \n",
    "    # some information\n",
    "    if debug_level>=1:\n",
    "        suicidal_behaviour_rate = train_Y.loc[train_Y['Class_suicidal_behaviour']==1].shape[0]/train_Y.shape[0]*100\n",
    "        n_non_yes_suicidal_behaviour = Counter(train_Y['Class_suicidal_behaviour'])\n",
    "        print('The rate of suicidal behaviour (1) AFTER rebalancing is: {:.2f}%'.format(suicidal_behaviour_rate))\n",
    "        print('Number of instances of each class')\n",
    "        print(n_non_yes_suicidal_behaviour)    \n",
    "    \n",
    "    # We scale the data\n",
    "    this_scaler = preprocessing.MinMaxScaler()\n",
    "    this_scaler = this_scaler.fit(train_X)\n",
    "    train_X = this_scaler.transform(train_X)\n",
    "    test_X = this_scaler.transform(test_X)\n",
    "    \n",
    "    \n",
    "    # we train the model with the rebalanced datasets\n",
    "    this_model.fit(train_X, np.ravel(train_Y))\n",
    "    \n",
    "    # we make the prediction about the test observations\n",
    "    predictions = this_model.predict(test_X)    \n",
    "    \n",
    "    # we calculate the confusion matrix over the test classes\n",
    "    conf_matrix = confusion_matrix(np.ravel(test_Y), np.ravel(predictions), labels=this_model.classes_)\n",
    "    tn, fp, fn, tp = conf_matrix.ravel()\n",
    "\n",
    "    # We recode the confusion matrix to make it more user-friendly.\n",
    "    #     1   0\n",
    "    # 1  tp  fn\n",
    "    # 0  fp  tn\n",
    "    \n",
    "    # we store the result of the confusion matrix in the global\n",
    "    all_conf_matrix[current_experiment] = [[tp,fn],[fp,tn]]\n",
    "    \n",
    "    # we store the statistics in the global\n",
    "    all_accuracy[current_experiment] = (tp+tn)/(tp+tn+fp+fn)*100\n",
    "    all_sensitivity[current_experiment] = tp/(tp+fn)*100\n",
    "    all_specificity[current_experiment] = tn/(tn+fp)*100\n",
    "    all_PPV_precision[current_experiment] = tp/(tp+fp)*100\n",
    "    all_NPV[current_experiment] = tn/(tn+fn)*100\n",
    "    all_FNR[current_experiment] = fn/(tp+fn)*100\n",
    "    all_F1[current_experiment] = (2*tp)/(2*tp+fp+fn)*100\n",
    "          \n",
    "    # some aditional information for every iteration\n",
    "    if debug_level>=2:\n",
    "        print('Confusion matrix:')\n",
    "        print(all_conf_matrix[current_experiment])\n",
    "        print('Accuracy: {:.3f}%'.format(all_accuracy[current_experiment]))\n",
    "        print('Sensitivity: {:.3f}%'.format(all_sensitivity[current_experiment]))\n",
    "        print('Specificity: {:.3f}%'.format(all_specificity[current_experiment]))\n",
    "        print('Positive Predictive Value (PPV or precision): {:.3f}%'.format(all_PPV_precision[current_experiment]))\n",
    "        print('Negative Predictive Value (NPV): {:.3f}%'.format(all_NPV[current_experiment]))\n",
    "        print('False Negative Rate (FNR): {:.3f}%'.format(all_FNR[current_experiment]))\n",
    "        print('F1: {:.3f}%'.format(all_F1[current_experiment]))\n",
    "        print('n: {}'.format(tp+fn+fp+tn))\n",
    "        print('\\n')     \n",
    "        \n",
    "    # we update to continue storing data\n",
    "    current_experiment = current_experiment + 1\n",
    "    \n",
    "# end for\n",
    "\n",
    "# Stop the timer\n",
    "timer_stop = process_time()\n",
    "\n",
    "\n",
    "# we print out the mean results and standard deviations\n",
    "mean_conf_matrix = np.mean(all_conf_matrix, axis=0)\n",
    "desvest_conf_matrix = np.std(all_conf_matrix, axis=0)\n",
    "print(\"\\n===============================\")\n",
    "print(\"SUMMARY FOR %d EXPERIMENTS\" % (total_experiments))\n",
    "print(\"\\nCONFUSION MATRIX MEAN VALUE (for experiments)\")\n",
    "print(mean_conf_matrix)\n",
    "print(\"\\nCONFUSION MATRIX STD VALUE (for experiments)\")\n",
    "print(desvest_conf_matrix)\n",
    "print('')\n",
    "print('Accuracy: {:.3f}% +- {:.3f}%'.format(all_accuracy.mean(),all_accuracy.std()))\n",
    "print('Sensitivity: {:.3f}% +- {:.3f}%'.format(all_sensitivity.mean(),all_sensitivity.std()))\n",
    "print('Specificity: {:.3f}% +- {:.3f}%'.format(all_specificity.mean(),all_specificity.std()))\n",
    "print('Positive Predictive Value (PPV or precision): {:.3f}% +- {:.3f}%'.format(all_PPV_precision.mean(),all_PPV_precision.std()))\n",
    "print('Negative Predictive Value (NPV): {:.3f}% +- {:.3f}%'.format(all_NPV.mean(),all_NPV.std()))\n",
    "print('False Negative Rate (FNR): {:.3f}% +- {:.3f}%'.format(all_FNR.mean(),all_FNR.std()))\n",
    "print('F1: {:.3f}% +- {:.3f}%'.format(all_F1.mean(),all_F1.std()))\n",
    "print('\\n')\n",
    "\n",
    "# we print out the elapsed time \n",
    "if debug_level>=0:\n",
    "    print(\"===============================\")\n",
    "    print(\"Elapsed time for execution (in seconds):\", timer_stop-timer_start) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# write results to file\n",
    "\n",
    "# Build name of file to represent configuration\n",
    "name = \"KNN\"\n",
    "name = name+\"_fold\"+str(folds)\n",
    "name = name+\"_rep\"+str(repetitions)\n",
    "name = name+\"_seed\"+str(seed)\n",
    "name = name+\"_weight\"+str(param_class_weight_min)+\"-\"+str(param_class_weight_max)\n",
    "name = name+\"_nNeighbors\"+str(param_n_neighbors)\n",
    "name = name+\"_weights\"+str(param_weights)\n",
    "name = name+\"_SMOTE\"+str(param_SMOTEsampling_strategy)\n",
    "name = name+\"_Under\"+str(param_Undersampling_strategy)\n",
    "name = name + \".txt\"\n",
    "\n",
    "with open(name, 'w') as f:\n",
    "    f.write(name)\n",
    "    f.write('\\n')\n",
    "    f.write('\\nAccuracy: {:.3f}% +- {:.3f}%'.format(all_accuracy.mean(),all_accuracy.std()))\n",
    "    f.write('\\nSensitivity: {:.3f}% +- {:.3f}%'.format(all_sensitivity.mean(),all_sensitivity.std()))\n",
    "    f.write('\\nSpecificity: {:.3f}% +- {:.3f}%'.format(all_specificity.mean(),all_specificity.std()))\n",
    "    f.write('\\nPositive Predictive Value (PPV or precision): {:.3f}% +- {:.3f}%'.format(all_PPV_precision.mean(),all_PPV_precision.std()))\n",
    "    f.write('\\nNegative Predictive Value (NPV): {:.3f}% +- {:.3f}%'.format(all_NPV.mean(),all_NPV.std()))\n",
    "    f.write('\\nFalse Negative Rate (FNR): {:.3f}% +- {:.3f}%'.format(all_FNR.mean(),all_FNR.std()))\n",
    "    f.write('\\nF1: {:.3f}% +- {:.3f}%'.format(all_F1.mean(),all_F1.std()))\n",
    "    f.write('\\n')\n",
    "    f.write('\\nall_accuracy = ')\n",
    "    f.write(np.array2string(all_accuracy, precision=3, separator=',',max_line_width=1000,suppress_small=True))\n",
    "    f.write('\\nall_sensitivity = ')\n",
    "    f.write(np.array2string(all_sensitivity, precision=3, separator=',',max_line_width=1000,suppress_small=True))\n",
    "    f.write('\\nall_specificity = ')\n",
    "    f.write(np.array2string(all_specificity, precision=3, separator=',',max_line_width=1000,suppress_small=True))\n",
    "    f.write('\\nall_PPV_precision = ')\n",
    "    f.write(np.array2string(all_PPV_precision, precision=3, separator=',',max_line_width=1000,suppress_small=True))\n",
    "    f.write('\\nall_NPV = ')\n",
    "    f.write(np.array2string(all_NPV, precision=3, separator=',',max_line_width=1000,suppress_small=True))\n",
    "    f.write('\\nall_FNR = ')\n",
    "    f.write(np.array2string(all_FNR, precision=3, separator=',',max_line_width=1000,suppress_small=True))\n",
    "    f.write('\\nall_F1 = ')\n",
    "    f.write(np.array2string(all_F1, precision=3, separator=',',max_line_width=1000,suppress_small=True))\n",
    "    f.write('\\n')\n",
    "    f.write(\"\\nElapsed time (seconds) = \")\n",
    "    f.write(str(timer_stop-timer_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
